{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install imageAI\n",
    "! pip install Pillow\n",
    "!pip install opencv-python\n",
    "!pip install cython pillow>=7.0.0 numpy>=1.18.1 opencv-python>=4.1.2 torch>=1.9.0 --extra-index-url https://download.pytorch.org/whl/cu102 torchvision>=0.10.0 --extra-index-url https://download.pytorch.org/whl/cu102 pytest==7.1.3 tqdm==4.64.1 scipy>=1.7.3 matplotlib>=3.4.3 mock==4.0.3\n",
    "!pip install cython pillow>=7.0.0 numpy>=1.18.1 opencv-python>=4.1.2 torch>=1.9.0 --extra-index-url https://download.pytorch.org/whl/cpu torchvision>=0.10.0 --extra-index-url https://download.pytorch.org/whl/cpu pytest==7.1.3 tqdm==4.64.1 scipy>=1.7.3 matplotlib>=3.4.3 mock==4.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import joblib\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imageai.Detection import VideoObjectDetection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection using Yolo pretrained data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_obj_detect = VideoObjectDetection()\n",
    "vid_obj_detect.setModelTypeAsYOLOv3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_obj_detect.setModelPath(\"yolov3.pt\")\n",
    "vid_obj_detect.loadModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "detected_vid_obj = vid_obj_detect.detectObjectsFromVideo(\n",
    "    input_file_path =  \"sample.mp4\",\n",
    "    output_file_path = \"output_video\",\n",
    "    frames_per_second=15,\n",
    "    log_progress=True,\n",
    "    return_detected_frame = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect frames with person using Yolo\n",
    "\n",
    "### For each frames, object detection with Yolo, retrieve frames with person detected.\n",
    "\n",
    "#### Two functions defined : 1 . Retrieve frame number where person are detected. 2. Save detected frames into output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forFrame(frame_number, output_array, output_count):\n",
    "    if 'person' in output_count:\n",
    "        frame_with_person.append(frame_number)\n",
    "\n",
    "def save_frames(video_path, frame_numbers, output_directory):\n",
    "    # Open the video file\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Iterate over the frame numbers\n",
    "    for frame_number in frame_numbers:\n",
    "        # Set the current frame number\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "        \n",
    "        # Read the frame\n",
    "        ret, frame = video.read()\n",
    "        \n",
    "        # If the frame was read successfully, save it as an image\n",
    "        if ret:\n",
    "            output_path = f\"{output_directory}/frame_{frame_number}.jpg\"\n",
    "            cv2.imwrite(output_path, frame)\n",
    "            print(f\"Frame {frame_number} saved as {output_path}\")\n",
    "        else:\n",
    "            print(f\"Error reading frame {frame_number}\")\n",
    "    \n",
    "    # Release the video file\n",
    "    video.release()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_path = os.getcwd()\n",
    "frame_with_person = []\n",
    "\n",
    "## loading Yolo models\n",
    "video_detector = VideoObjectDetection()\n",
    "video_detector.setModelTypeAsYOLOv3()\n",
    "video_detector.setModelPath(os.path.join(execution_path, \"yolov3.pt\"))\n",
    "video_detector.loadModel()\n",
    "\n",
    "## Detecting person in each frame, save detected frames in file output\n",
    "video_detector.detectObjectsFromVideo(input_file_path=os.path.join(execution_path, \"sample.mp4\"), output_file_path=os.path.join(execution_path, \"video_frame_analysis\") ,  frames_per_second=20, per_frame_function=forFrame,  minimum_percentage_probability=30)\n",
    "video_path = \"sample.mp4\"\n",
    "frame_numbers = frame_with_person  # Frame numbers to retrieve\n",
    "output_directory = \"output\"\n",
    "\n",
    "save_frames(video_path, frame_numbers, output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML models for staff detection for all the frames that detected with person previously\n",
    "\n",
    "### Data Preprocess\n",
    "\n",
    "10 images for staff exists and 10 images for staff does not exists are selected from the frames retrieved previously. \n",
    "Both save in folder **train_yes** and **train_no** respectively. Selected images are removed from output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data preparation and preprocessing\n",
    "# Path to the directories containing the staff and non-staff images\n",
    "staff_images_dir = 'train_yes'\n",
    "non_staff_images_dir = 'train_no'\n",
    "\n",
    "# Load staff images\n",
    "staff_images = []\n",
    "for filename in os.listdir(staff_images_dir):\n",
    "    image = Image.open(os.path.join(staff_images_dir, filename))\n",
    "    image = image.resize((64, 64))  # Resize the images to a consistent size\n",
    "    staff_images.append(np.array(image))\n",
    "\n",
    "# Load non-staff images\n",
    "non_staff_images = []\n",
    "for filename in os.listdir(non_staff_images_dir):\n",
    "    image = Image.open(os.path.join(non_staff_images_dir, filename))\n",
    "    image = image.resize((64, 64))  # Resize the images to a consistent size\n",
    "    non_staff_images.append(np.array(image))\n",
    "\n",
    "# Combine the staff and non-staff images into a single dataset\n",
    "X = np.concatenate((staff_images, non_staff_images), axis=0)\n",
    "y = np.concatenate((np.ones(len(staff_images)), np.zeros(len(non_staff_images))), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split, Training and testing data using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the image pixel values to improve model performance\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.reshape(len(X_train), -1))\n",
    "X_test_scaled = scaler.transform(X_test.reshape(len(X_test), -1))\n",
    "\n",
    "# Step 2: Model training\n",
    "# Create a support vector machine (SVM) classifier\n",
    "svm = SVC(kernel='rbf', C=1.0, random_state=42)\n",
    "\n",
    "# Train the SVM classifier\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Step 3: Model evaluation\n",
    "# Predict the labels for the test set\n",
    "y_pred = svm.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict data not seen by the model (data stored in test folder) for inference, Model saved as pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Inference\n",
    "# Load and preprocess a new image for prediction\n",
    "new_image = Image.open('test/frame_380.jpg')\n",
    "new_image = new_image.resize((64, 64))  # Resize the image to match the training data\n",
    "new_image_scaled = scaler.transform(np.array(new_image).reshape(1, -1))\n",
    "\n",
    "# Make a prediction on the new image\n",
    "prediction = svm.predict(new_image_scaled)\n",
    "if prediction[0] == 1:\n",
    "    print(\"The image contains a staff.\")\n",
    "else:\n",
    "    print(\"The image does not contain a staff.\")\n",
    "    \n",
    "# Save the trained model\n",
    "joblib.dump(svm, 'staff_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For remaining unpredicted images in output folder, predict whether the staff exists\n",
    "\n",
    "#### After detection, result are separted into two folders, one with staff and one without, frames with staff are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = 'output'\n",
    "frame_with_staff_tag = []\n",
    "\n",
    "## load saved model\n",
    "svm = SVC(kernel='rbf', C=1.0, random_state=42)\n",
    "svm = joblib.load('staff_model.pkl')\n",
    "\n",
    "## result folders\n",
    "staff_folder = 'test_staff_result_frame'\n",
    "non_staff_folder = 'test_non_staff_result_frame'\n",
    "\n",
    "# Preprocess images and make predictions\n",
    "for filename in os.listdir(images_dir):\n",
    "    image_path = os.path.join(images_dir, filename)\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((64, 64))  # Resize the image to match the training data\n",
    "\n",
    "    # Preprocess the image for prediction\n",
    "    image_scaled = scaler.transform(np.array(image).reshape(1, -1))\n",
    "\n",
    "    # Make a prediction on the image\n",
    "    prediction = svm.predict(image_scaled)\n",
    "\n",
    "    if prediction[0] == 1:\n",
    "        frame_with_staff_tag.append(filename)\n",
    "        shutil.copy(image_path, os.path.join(staff_folder, filename))\n",
    "    else:\n",
    "        shutil.copy(image_path, os.path.join(non_staff_folder, filename))\n",
    "        \n",
    "print(\"Frames with staff : \")\n",
    "print(frame_with_staff_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
